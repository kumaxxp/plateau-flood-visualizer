{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLATEAU ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€PLATEAUã®3Déƒ½å¸‚ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†ã—ã€æ°´æ²¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã§ãã‚‹å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mgpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import folium\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"plateau\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {DATA_DIR}\")\n",
    "print(f\"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ—¢å­˜ã®GMLãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢\n",
    "gml_files = list(DATA_DIR.glob(\"*_bldg_*.gml\"))\n",
    "geojson_files = list(DATA_DIR.glob(\"*.geojson\"))\n",
    "\n",
    "print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ:\")\n",
    "print(f\"  GMLãƒ•ã‚¡ã‚¤ãƒ«: {len(gml_files)}å€‹\")\n",
    "print(f\"  GeoJSONãƒ•ã‚¡ã‚¤ãƒ«: {len(geojson_files)}å€‹\")\n",
    "\n",
    "if gml_files:\n",
    "    print(f\"\\næœ€åˆã®5å€‹ã®GMLãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    for f in gml_files[:5]:\n",
    "        print(f\"  - {f.name}\")\n",
    "\n",
    "if geojson_files:\n",
    "    print(f\"\\nGeoJSONãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    for f in geojson_files:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GMLãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ï¼ˆCityGML â†’ GeoJSONå¤‰æ›ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gml_files(gml_files, max_files=10, sample_rate=1.0):\n",
    "    \"\"\"\n",
    "    GMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦GeoDataFrameã«å¤‰æ›\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gml_files : list\n",
    "        å‡¦ç†ã™ã‚‹GMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ\n",
    "    max_files : int\n",
    "        å‡¦ç†ã™ã‚‹æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«æ•°\n",
    "    sample_rate : float\n",
    "        å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹å‰²åˆï¼ˆ0.0-1.0ï¼‰\n",
    "    \"\"\"\n",
    "    all_buildings = []\n",
    "    processed_files = 0\n",
    "    \n",
    "    # å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’åˆ¶é™\n",
    "    files_to_process = gml_files[:min(max_files, len(gml_files))]\n",
    "    \n",
    "    print(f\"ğŸ”„ {len(files_to_process)}å€‹ã®GMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™...\")\n",
    "    \n",
    "    for gml_file in tqdm(files_to_process, desc=\"GMLå‡¦ç†ä¸­\"):\n",
    "        try:\n",
    "            # GMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
    "            gdf = gpd.read_file(gml_file, driver='GML')\n",
    "            \n",
    "            if len(gdf) == 0:\n",
    "                continue\n",
    "            \n",
    "            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "            if sample_rate < 1.0:\n",
    "                gdf = gdf.sample(frac=sample_rate)\n",
    "            \n",
    "            # å»ºç‰©ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º\n",
    "            for idx, row in gdf.iterrows():\n",
    "                if row.geometry is None:\n",
    "                    continue\n",
    "                \n",
    "                building = {\n",
    "                    'geometry': row.geometry,\n",
    "                    'source_file': gml_file.name\n",
    "                }\n",
    "                \n",
    "                # é«˜ã•æƒ…å ±ã‚’å–å¾—\n",
    "                height_columns = ['measuredHeight', 'bldg:measuredHeight', 'height', 'Height']\n",
    "                height = 20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤\n",
    "                \n",
    "                for col in height_columns:\n",
    "                    if col in row and pd.notna(row[col]):\n",
    "                        try:\n",
    "                            height = float(row[col])\n",
    "                            break\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                building['height'] = height\n",
    "                building['ground_height'] = 0\n",
    "                \n",
    "                # ãã®ä»–ã®å±æ€§\n",
    "                if 'usage' in row:\n",
    "                    building['usage'] = str(row['usage'])\n",
    "                \n",
    "                all_buildings.append(building)\n",
    "            \n",
    "            processed_files += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ ã‚¨ãƒ©ãƒ¼ ({gml_file.name}): {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nâœ… {processed_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰{len(all_buildings)}ä»¶ã®å»ºç‰©ã‚’æŠ½å‡º\")\n",
    "    \n",
    "    if all_buildings:\n",
    "        return gpd.GeoDataFrame(all_buildings)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†\n",
    "if gml_files:\n",
    "    buildings_gdf = process_gml_files(gml_files, max_files=10, sample_rate=0.5)\n",
    "    \n",
    "    if buildings_gdf is not None:\n",
    "        # åº§æ¨™ç³»ã‚’è¨­å®š\n",
    "        buildings_gdf.set_crs('EPSG:4326', allow_override=True, inplace=True)\n",
    "        \n",
    "        # çµ±è¨ˆæƒ…å ±\n",
    "        print(f\"\\nğŸ“Š å»ºç‰©ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:\")\n",
    "        print(f\"  ç·å»ºç‰©æ•°: {len(buildings_gdf):,}\")\n",
    "        print(f\"  å¹³å‡é«˜ã•: {buildings_gdf['height'].mean():.1f}m\")\n",
    "        print(f\"  æœ€é«˜: {buildings_gdf['height'].max():.1f}m\")\n",
    "        print(f\"  æœ€ä½: {buildings_gdf['height'].min():.1f}m\")\n",
    "        \n",
    "        # GeoJSONã¨ã—ã¦ä¿å­˜\n",
    "        output_file = DATA_DIR / \"tokyo_bldg.geojson\"\n",
    "        buildings_gdf.to_file(output_file, driver='GeoJSON')\n",
    "        print(f\"\\nğŸ’¾ ä¿å­˜å®Œäº†: {output_file}\")\n",
    "else:\n",
    "    print(\"âš ï¸ GMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    buildings_gdf = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä»£æ›¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆGMLãŒãªã„å ´åˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_tokyo_data():\n",
    "    \"\"\"æ±äº¬ã®ä¸»è¦ã‚¨ãƒªã‚¢ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\"\"\"\n",
    "    \n",
    "    # æ±äº¬ã®ä¸»è¦ã‚¨ãƒªã‚¢\n",
    "    areas = {\n",
    "        \"æ±äº¬é§…\": {\"center\": [139.7671, 35.6812], \"buildings\": 50, \"avg_height\": 150},\n",
    "        \"æ–°å®¿\": {\"center\": [139.7003, 35.6938], \"buildings\": 60, \"avg_height\": 180},\n",
    "        \"æ¸‹è°·\": {\"center\": [139.7019, 35.6580], \"buildings\": 50, \"avg_height\": 120},\n",
    "        \"å“å·\": {\"center\": [139.7388, 35.6284], \"buildings\": 40, \"avg_height\": 100},\n",
    "        \"ãŠå°å ´\": {\"center\": [139.7744, 35.6311], \"buildings\": 30, \"avg_height\": 60},\n",
    "    }\n",
    "    \n",
    "    from shapely.geometry import Polygon\n",
    "    \n",
    "    all_buildings = []\n",
    "    \n",
    "    for area_name, info in areas.items():\n",
    "        lon, lat = info[\"center\"]\n",
    "        \n",
    "        for i in range(info[\"buildings\"]):\n",
    "            # ãƒ©ãƒ³ãƒ€ãƒ ãªä½ç½®\n",
    "            offset_lon = np.random.normal(0, 0.002)\n",
    "            offset_lat = np.random.normal(0, 0.002)\n",
    "            \n",
    "            # å»ºç‰©ã®ä½ç½®\n",
    "            bldg_lon = lon + offset_lon\n",
    "            bldg_lat = lat + offset_lat\n",
    "            \n",
    "            # å»ºç‰©ã®ã‚µã‚¤ã‚º\n",
    "            size = 0.0001 * np.random.uniform(0.5, 1.5)\n",
    "            \n",
    "            # ãƒãƒªã‚´ãƒ³ä½œæˆ\n",
    "            poly = Polygon([\n",
    "                (bldg_lon - size/2, bldg_lat - size/2),\n",
    "                (bldg_lon + size/2, bldg_lat - size/2),\n",
    "                (bldg_lon + size/2, bldg_lat + size/2),\n",
    "                (bldg_lon - size/2, bldg_lat + size/2)\n",
    "            ])\n",
    "            \n",
    "            # é«˜ã•\n",
    "            height = np.random.normal(info[\"avg_height\"], info[\"avg_height\"] * 0.3)\n",
    "            height = max(10, min(250, height))  # 10-250mã«åˆ¶é™\n",
    "            \n",
    "            all_buildings.append({\n",
    "                'geometry': poly,\n",
    "                'height': height,\n",
    "                'ground_height': np.random.uniform(0, 5),\n",
    "                'area': area_name\n",
    "            })\n",
    "    \n",
    "    return gpd.GeoDataFrame(all_buildings, crs='EPSG:4326')\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
    "if buildings_gdf is None:\n",
    "    print(\"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™...\")\n",
    "    buildings_gdf = create_sample_tokyo_data()\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    output_file = DATA_DIR / \"tokyo_bldg.geojson\"\n",
    "    buildings_gdf.to_file(output_file, driver='GeoJSON')\n",
    "    print(f\"âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {output_file}\")\n",
    "    print(f\"   å»ºç‰©æ•°: {len(buildings_gdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç‰©ã®åˆ†å¸ƒã‚’åœ°å›³ä¸Šã«è¡¨ç¤º\n",
    "if buildings_gdf is not None and len(buildings_gdf) > 0:\n",
    "    # ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—\n",
    "    bounds = buildings_gdf.total_bounds\n",
    "    center_lat = (bounds[1] + bounds[3]) / 2\n",
    "    center_lon = (bounds[0] + bounds[2]) / 2\n",
    "    \n",
    "    # Foliumãƒãƒƒãƒ—ã‚’ä½œæˆ\n",
    "    m = folium.Map(location=[center_lat, center_lon], zoom_start=13)\n",
    "    \n",
    "    # å»ºç‰©ã‚’è¿½åŠ ï¼ˆæœ€å¤§100å€‹ã¾ã§ï¼‰\n",
    "    for idx, building in buildings_gdf.head(100).iterrows():\n",
    "        # ãƒãƒªã‚´ãƒ³ã®ä¸­å¿ƒã‚’è¨ˆç®—\n",
    "        centroid = building.geometry.centroid\n",
    "        \n",
    "        # é«˜ã•ã«ã‚ˆã£ã¦è‰²ã‚’å¤‰ãˆã‚‹\n",
    "        if building['height'] > 100:\n",
    "            color = 'red'\n",
    "        elif building['height'] > 50:\n",
    "            color = 'orange'\n",
    "        else:\n",
    "            color = 'green'\n",
    "        \n",
    "        # ãƒãƒ¼ã‚«ãƒ¼ã‚’è¿½åŠ \n",
    "        folium.CircleMarker(\n",
    "            location=[centroid.y, centroid.x],\n",
    "            radius=3,\n",
    "            popup=f\"é«˜ã•: {building['height']:.1f}m\",\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fillColor=color\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # åœ°å›³ã‚’è¡¨ç¤º\n",
    "    display(m)\n",
    "    print(f\"\\nğŸ—ºï¸ {min(100, len(buildings_gdf))}ä»¶ã®å»ºç‰©ã‚’åœ°å›³ä¸Šã«è¡¨ç¤º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ°´æ²¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«ãƒ‘ã‚¹ã‚’è¿½åŠ \n",
    "import sys\n",
    "sys.path.append(str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "try:\n",
    "    from simulator import FloodSimulator\n",
    "    from visualizer import FloodVisualizer\n",
    "    \n",
    "    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ\n",
    "    sim = FloodSimulator(\"tokyo\", data_dir=DATA_DIR)\n",
    "    sim.load_buildings()\n",
    "    \n",
    "    # æ°´ä½10mã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "    results = sim.simulate_flood(water_level=10.0)\n",
    "    \n",
    "    print(\"\\nğŸŒŠ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœï¼ˆæ°´ä½10mï¼‰:\")\n",
    "    print(f\"  å®Œå…¨æ°´æ²¡: {results['flooded_buildings']}æ£Ÿ ({results['flooded_percentage']:.1f}%)\")\n",
    "    print(f\"  éƒ¨åˆ†æ°´æ²¡: {results['partially_flooded']}æ£Ÿ\")\n",
    "    print(f\"  å½±éŸ¿ç‡: {results['affected_percentage']:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"src/simulator.pyãŒå¿…è¦ã§ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. è¤‡æ•°æ°´ä½ã§ã®å½±éŸ¿åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¤‡æ•°ã®æ°´ä½ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "water_levels = [2, 5, 10, 15, 20, 30]\n",
    "results_list = []\n",
    "\n",
    "if buildings_gdf is not None:\n",
    "    print(\"ğŸ“Š æ°´ä½åˆ¥å½±éŸ¿åˆ†æ:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'æ°´ä½(m)':>8} | {'å½±éŸ¿å»ºç‰©':>10} | {'å®Œå…¨æ°´æ²¡':>10} | {'å½±éŸ¿ç‡':>8}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for level in water_levels:\n",
    "        # ç°¡æ˜“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "        flood_depth = level - buildings_gdf['ground_height']\n",
    "        flooded = (flood_depth > buildings_gdf['height']).sum()\n",
    "        partial = ((flood_depth > 0) & (flood_depth <= buildings_gdf['height'])).sum()\n",
    "        affected_pct = (flooded + partial) / len(buildings_gdf) * 100\n",
    "        \n",
    "        print(f\"{level:8.0f} | {flooded + partial:10d} | {flooded:10d} | {affected_pct:7.1f}%\")\n",
    "        \n",
    "        results_list.append({\n",
    "            'water_level': level,\n",
    "            'flooded': flooded,\n",
    "            'partial': partial,\n",
    "            'affected_pct': affected_pct\n",
    "        })\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. çµæœã®ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜\n",
    "summary = {\n",
    "    'processed_date': pd.Timestamp.now().isoformat(),\n",
    "    'data_source': 'PLATEAU GML' if gml_files else 'Sample Data',\n",
    "    'total_buildings': len(buildings_gdf) if buildings_gdf is not None else 0,\n",
    "    'simulation_results': results_list\n",
    "}\n",
    "\n",
    "# JSONã¨ã—ã¦ä¿å­˜\n",
    "summary_file = OUTPUT_DIR / 'plateau_processing_summary.json'\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"ğŸ“„ ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜: {summary_file}\")\n",
    "print(\"\\nâœ… å‡¦ç†å®Œäº†ï¼\")\n",
    "print(\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "print(\"1. python src/main.py simulate tokyo --level 10\")\n",
    "print(\"2. python src/main.py server --port 8001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
